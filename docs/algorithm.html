<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Group 7 Algorithm</title>
        <link rel="stylesheet" type="text/css" href="css/style.css"/>
    </head>
    <body>
        <header>
           <h1>Datalogical Thinking Project: Just Google it</h1>
         <nav>
         
                <a href="index.html">Home</a>
                <a href="dataset.html">Dataset</a>
                <a class="active" href="algorithm.html">Algorithm</a>
                <a href="output.html">Output</a>
                <a href="discussion.html">Discussion</a>
                <a href="people.html">People</a>
           
        </nav>
        </header>
        <main>
                <h2>Our algorithm</h2>
        <p>After we had edited the data in several processes, the next step was to create an algorithm. However, it should be noted that the steps of data curation and algorithm building go hand in hand and are often a trial-and-error case. We often adjusted when the results didn´t appear as expected. As a group, we thought together about the algorithm and had to curate the dataset to build our algorithm accurately. We pragmatically defined what the algorithm should do in simple, natural language.</p>

        <p>An algorithm can be described as a plan of a solution, a set of instructions for solving a problem in a finite amount of time using a finite amount of data. Pseudocode then serves as the readable description of this algorithm - written in everyday language it serves as a bridge between natural language and a programming language, such as, in our case, Python.</p> 


<p>With the help of pseudocode, we described the algorithm and formulated the following steps:
</p>
<ol>
<li>
Initialisation of data and variables.<br>
 Read our curated data from the CSV file and read it into a DataFrame.<br> 
    This should result in two lists: Remove Keyword and Top 5 Keyword.
</li>

<li>
 Interactive exclusion process of the keywords.<br>
 Identify the five most frequent keywords and save them in the Top 5 Keywords list.<br> An interactive process should then allow users to remove a specific keyword from the Top 5 Keywords list through a loop if necessary until they indicate completion.   
</li>
    <li>
    Filter the articles associated with the top keywords.<br>
 Now take the remaining top 5 keywords and filter out the articles from the dataset that are related to these keywords.
</li>
    <li>
    Identify the authors and the articles.<br>
 Check each of the articles to see if one of the top 5 keywords is included.<br>
        List the relevant headers (keyword, author, title, permalink and description).<br>
        Remove duplicates to guarantee the uniqueness of the single entries. 
</li>
    <li>
    Generate a word cloud.<br>
 Merge all descriptions from the filtered articles into a single string.<br> Then generate a word cloud based on the merged text.<br> Save the word cloud as SVG and encode it for HTML display.
</li>
    <li>
     Generate output files.<br>
 Create a Markdown file to summarise the keyword analysis and list the articles.<br> 
        Now generate an HTML report that includes sections for top keywords, relevant articles, authors discussing the keywords, and the world cloud.
</li>
</ol>

<h3>Which problems occurred in the algorithm process?</h3> 


<p>In our case, Victor agreed to deal with the algorithm process and thus with writing the pseudocode. Over time, however, it became apparent that there was no common basis on which to base our terms. In concrete terms, this means that for example Klara had difficulty formulating her expectations of the algorithm and the data visualisation, and conversely, Victor had difficulty understanding Klara's expectations, as the terms were often unknown or interpreted differently. These different kinds of approaches have led us to make improvements within our research questions in order to make the overall picture of our dataset coherent in combination with the algorithm. It should be also mentioned here that there were different expectations within our group as to how queries to the algorithm should be visualised. Only after a long back and forth, further editing of the research question and a meeting did we manage to adapt our research questions so that they match what the algorithm can visualize. This leads us to the point of the different skills and experiences from everyone in the group. As a result, we sometimes talked past each other in meetings.The communication, which went very well within the group in general, should have been edited earlier at a technical level. To see where everyone's level on this project is. A good example would be the joint determination of a language usage. This means, for example: Is pseudocode our algorithm? How “easy” is it to change codes? And how can/should we visualise our data?</p> 


<h2>The algorithm in Pseudocode</h2>
<code>
    ALGORITHM Generate_Report<br>
    <br>
    INPUT: CSV file path, Markdown file path<br>
    OUTPUT: Markdown report with keywords, articles, and word cloud<br>
    <br>
    BEGIN<br>
        # Load the dataset<br>
        LOAD CSV INTO dataframe df<br>
        <br>
        # Initialize variables<br>
        SET removed_keywords TO empty list<br>
        SET top_5_keywords TO empty list<br>
        <br>
        # Loop for displaying and removing top 5 keywords<br>
        WHILE True DO<br>
            IF top_5_keywords IS empty THEN<br>
                SET all_keywords TO explode and clean keywords from df<br>
                SET keyword_counts TO top 5 keyword counts from all_keywords<br>
                SET top_5_keywords TO indices of keyword_counts<br>
            ELSE<br>
                SET all_keywords TO explode and clean keywords from df<br>
                SET keyword_counts TO all keyword counts from all_keywords<br>
                SET top_5_keywords TO filter out removed keywords from keyword_counts<br>
                <br>
            PRINT top 5 keywords and frequencies<br>
            <br>
            # Get user input for removing keywords<br>
            SET user_input TO get user input<br>
            IF user_input IS 'done' THEN<br>
                BREAK<br>
            ELSE<br>
                PARSE user_input<br>
                UPDATE removed_keywords and top_5_keywords<br>
                <br>
        # Create string of all keywords and their frequencies<br>
        SET all_keywords_str TO create string from top_5_keywords<br>
        <br>
        # Filter dataframe for articles matching top 5 keywords<br>
        SET filtered_df TO filter df based on top_5_keywords<br>
        <br>
        # Generate and save word cloud<br>
        SET descriptions_top_keywords TO join descriptions from filtered_df<br>
        GENERATE word cloud from descriptions_top_keywords<br>
        SAVE word cloud as SVG and PNG files<br>
        <br>
        # Write results to markdown file<br>
        OPEN markdown file for writing<br>
        WRITE dataset report header<br>
        WRITE top 5 keywords and their frequencies<br>
        WRITE all keywords and their frequencies<br>
        WRITE articles matching top 5 keywords<br>
        WRITE wordcloud image embedding (SVG with PNG fallback)<br>
    END

</code>

            <h2>The algorithm in Python</h2>
                <code>
import pandas as pd<br>
from wordcloud import WordCloud<br>
import base64<br>
from io import BytesIO<br>
import matplotlib.pyplot as plt<br>
<br>

# Read the dataset from CSV<br>
input_file_path = "/data/dataset.csv"<br>
md_file_path = "Report.md"  # Replace with the desired markdown file path<br>
df = pd.read_csv(input_file_path)<br>
<br>


# Interactive keyword exclusion process<br>
removed_keywords = []  # Initialize removed keywords list<br>
top_5_keywords = []<br>
<br>
    # Task 1: Display top 5 keywords and their frequencies<br>
    while True:<br>
    if not top_5_keywords:  # If the top 5 keywords are not yet populated<br>
        all_keywords = df['Keywords'].str.split(';').explode().str.strip()<br>
        keyword_counts = all_keywords.value_counts().head(5)<br>
        top_5_keywords = keyword_counts.index.tolist()<br>
    else:  # If we already have top 5 keywords, remove those that the user has marked for removal<br>
        all_keywords = df['Keywords'].str.split(';').explode().str.strip()<br>
        keyword_counts = all_keywords.value_counts()<br>
        top_5_keywords = [keyword for keyword, count in keyword_counts.items() if keyword not in removed_keywords][:5]<br>
    <br>

    print("\nCurrent Top Keywords and Their Frequencies:")<br>
    for idx, keyword in enumerate(top_5_keywords):<br>
    count = keyword_counts.get(keyword, 0)<br>
        print(f"{idx + 1}. {keyword}")<br>
<br>

    user_input = input("Enter the number of the keyword you want to remove (comma-separated if multiple), or 'done' to finish: ")<br>
    if user_input.lower() == 'done':<br>
        break<br>
    try:<br>
        to_remove = [int(num) - 1 for num in user_input.split(',')]<br>
        removed_keywords.extend([top_5_keywords[i] for i in to_remove])
        top_5_keywords = [keyword for keyword in top_5_keywords if keyword not in removed_keywords]<br>
    except ValueError:<br>
        print("Invalid input. Please enter the number(s) of the keyword you want to remove.")<br>
<br>

# Task 1.1 : Display all keywords and their frequencies as a single line<br>
all_keywords_str = ""  # Initialize the string before the loop<br>
for idx, keyword in enumerate(top_5_keywords):<br>
    count = keyword_counts.get(keyword, 0)<br>
    print(f"Appending: {keyword}{count}")<br>
    all_keywords_str += f"{keyword}{count}, "  # Append to the existing string<br>
    <br>
# Remove the trailing comma and space<br>
all_keywords_str = all_keywords_str.strip(', ')<br>
print(f"\nAll Keywords and Their Frequencies: {all_keywords_str}")<br>
<br>
# Task 2: Articles matching the top 5 keywords after removal<br>
filtered_df = df[df['Keywords'].str.contains('|'.join(top_5_keywords), na=False)]<br>
print("\nArticles Matching the Top 5 Keywords:")<br> 
for idx, row in filtered_df.iterrows():<br>
print(f"{idx + 1}. {row.get('Title', 'No Title')}")<br>
<br>
# Task 4: Word cloud based on descriptions of articles matching the remaining top 5 keywords<br>
descriptions_top_keywords = ' '.join(filtered_df['Description'].dropna())  # join all descriptions in a single string, dropping NaNs<br>
wordcloud = WordCloud(width=1200, height=960).generate(descriptions_top_keywords)  # generate word cloud with the joined descriptions<br>
<br>
# Save the word cloud as SVG<br>
wordcloud_svg = wordcloud.to_svg(embed_font=False)<br>
with open("data/img/Descriptions_word_cloud.svg", "w") as f:<br>
    f.write(wordcloud_svg)<br>
    <br>
# Save the word cloud as PNG<br>
wordcloud.to_file("data/img/Descriptions_word_cloud.png")<br>
<br>
print("Word cloud saved to data/img/Descriptions_word_cloud.svg and Descriptions_word_cloud.png")<br>
<br>
# Write the results to a markdown file<br>
with open(md_file_path, 'w') as md:<br>
    md.write("# Dataset report\n\n")<br>
    md.write("**Top 5 Keywords and Their Frequencies**\n\n")<br>
    for idx, keyword in enumerate(top_5_keywords):<br>
        count = keyword_counts.get(keyword, 0)<br>
        status = "[removed by user]" if keyword in removed_keywords else ""<br>
        md.write(f"{idx + 1}. {keyword} ({count}) {status}\n")<br>
        <br>
    # Construct all_keywords_str_md correctly<br>
    all_keywords_str_md = ', '.join([f"{keyword} (**{keyword_counts.get(keyword, 0)}**) {'||**removed by user**| ' if keyword in removed_keywords else ''}" for keyword in keyword_counts.index])<br>
    md.write("\n**All Keywords and Their Frequencies**\n\n")<br>
    md.write(f"{all_keywords_str_md}\n\n")<br>
    md.write("**Articles Matching the Top 5 Keywords**\n\n")<br>
    <br>
    articles_by_keyword = {}<br>
    # Group articles by keywords<br>
    for idx, row in filtered_df.iterrows():<br>
        for keyword in top_5_keywords:<br>
            if keyword in row['Keywords']:<br>
                if keyword not in articles_by_keyword:<br>
                    articles_by_keyword[keyword] = []<br>
                article_info = {<br>
                    'title': row.get('Title', 'No Title'),<br>
                    'authors': row.get('Author', 'No Author').split(';'),  # Split authors by ';'<br>
                    'permalink': row.get('Permalink', '#')<br>
                }<br>
                articles_by_keyword[keyword].append(article_info)<br>
                <br>
    # Write each group of articles<br>
    article_idx = 1<br>
    for keyword, articles in articles_by_keyword.items():<br>
        md.write(f"\n\n{keyword} ({len(articles)})\n")<br>
        for article in articles:<br>
            title = article['title']<br>
            authors = '\n'.join([f"**{article_idx}.**  {author}" for author in article['authors']])<br>
            permalink = article['permalink']<br>
            md.write(f"{authors} **|** <a href='{permalink}'>{title}</a>\n")<br>
            article_idx += 1<br>
            <br>
    md.write("\n\n**Wordcloud based on the descriptions of the articles matching the top five keywords**\n\n")<br>
    md.write('<img src="data/img/Descriptions_word_cloud.svg" onerror="this.onerror=null;this.src=\'data/img/Descriptions_word_cloud.png\';">')<br>
    <br>
print(f"Results saved to {md_file_path}")
                </code>
        </main>
       <footer>
            <div id="footer">
               <div class="copyright">
                  <div><a href="https://creativecommons.org/licenses/by/4.0/legalcode"><img src="img/cc.svg" class="copyright_logo" alt="Creative Commons License"><img src="img/by.svg" class="copyright_logo" alt="Attribution 4.0 International"></a></div>
                  <div>
                     2024 Klara Chlupata, Einar Hannerz, Andre Rodewald and Victor Villavicencio.
                     </div>
               </div>
            </div>
         </footer>
    </body>
</html>
