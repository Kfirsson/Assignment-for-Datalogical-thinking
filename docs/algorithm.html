<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <title>Group 7 Algorithm</title>
        <link rel="stylesheet" type="text/css" href="css/style.css"/>
    </head>
    <body>
        <header>
           <h1>Datalogical Thinking Project: Just Google it</h1>
         <nav>
         
                <a href="index.html">Home</a>
                <a href="dataset.html">Dataset</a>
                <a class="active" href="algorithm.html">Algorithm</a>
                <a href="output.html">Output</a>
                <a href="people.html">People</a>
           
        </nav>
        </header>
        <main>
                <h2>Our algorithm</h2>
        <p>After we had edited the data in several processes, the next step was to create an algorithm. However, it should be noted that the steps of data curation and algorithm building go hand in hand and are often a trial-and-error case. We often adjusted when the results didnÂ´t appear as expected. As a group, we thought together about the algorithm and had to curate the dataset to build our algorithm accurately. We pragmatically defined what the algorithm should do in simple, natural language.</p>
<p> To briefly explain how an algorithm works, it is worth looking at the literature. Dale and Lewis state that an algorithm can be described as a plan of a solution. It contains a set of instructions for solving problems or subproblems in a finite amount of time using a finite amount of data (Dale & Lewis, 2019). To describe it a little more vividly, working with the data and an algorithm can be compared to a baking recipe, ergo a step-by-step guide. The ingredients are the input data and the recipe, i.e. the step-by-step instructions, is the algorithm.
</p>
            <p>Pseudocode serves as a readable description of the algorithm. The special feature here is that pseudocode does not belong to a programming language but is written in everyday language and is therefore generally easier to implement. Pseudocode serves as a bridge or interface between a natural language and a programming language (in our case HTML). With the help of pseudocode, we described the algorithm and formulated the following steps:
</p>
<ol>
<li>
Initialisation of data and variables.<br>
 Read our curated data from the CSV file and read it into a DataFrame.<br> 
    This should result in two lists: Remove Keyword and Top 5 Keyword.
</li>

<li>
 Interactive exclusion process of the keywords.<br>
 Identify the five most frequent keywords and save them in the Top 5 Keywords list.<br> An interactive process should then allow users to remove a specific keyword from the Top 5 Keywords list through a loop if necessary until they indicate completion.   
</li>
    <li>
    Filter the articles associated with the top keywords.<br>
 Now take the remaining top 5 keywords and filter out the articles from the dataset that are related to these keywords.
</li>
    <li>
    Identify the authors and the articles.<br>
 Check each of the articles to see if one of the top 5 keywords is included.<br>
        List the relevant headers (keyword, author, title, permalink and description).<br>
        Remove duplicates to guarantee the uniqueness of the single entries. 
</li>
    <li>
    Generate a word cloud.<br>
 Merge all descriptions from the filtered articles into a single string.<br> Then generate a word cloud based on the merged text.<br> Save the word cloud as SVG and encode it for HTML display.
</li>
    <li>
     Generate output files.<br>
 Create a Markdown file to summarise the keyword analysis and list the articles.<br> 
        Now generate an HTML report that includes sections for top keywords, relevant articles, authors discussing the keywords, and the world cloud.
</li>
</ol>
            <h3>The algorithm in Python</h3>
                <code>
import pandas as pd<br>
from wordcloud import WordCloud, ImageColorGenerator<br>
import base64<br>
from io import BytesIO<br>
import matplotlib.pyplot as plt<br>
from collections import Counter<br>
import re<br>
<br>
# Read the dataset from CSV<br>
df = pd.read_csv('NewsDB-Python/datasets/dataset.csv')<br>
<br>
# Initialize removed keywords list<br>
removed_keywords = []<br>
<br>
# Interactive keyword exclusion process<br>
top_5_keywords = []<br>
while True:<br>
    # Task 1: Display top 5 keywords and their frequencies<br>
    if not top_5_keywords:  # If the top 5 keywords are not yet populated<br>
        all_keywords = df['Keywords'].str.split(';').explode().str.strip()<br>
        keyword_counts = all_keywords.value_counts().head(5)<br>
        top_5_keywords = keyword_counts.index.tolist()<br>
    else:  # If we already have top 5 keywords, remove those that the user has marked for removal<br>
        all_keywords = df['Keywords'].str.split(';').explode().str.strip()<br>
        keyword_counts = all_keywords.value_counts()<br>
        top_5_keywords = [keyword for keyword, count in keyword_counts.items() if keyword not in removed_keywords][:5]<br>
    <br>
    print("\nCurrent Top Keywords and Their Frequencies:")<br>
    for idx, keyword in enumerate(top_5_keywords):<br>
        print(f"{idx + 1}. {keyword}")<br>
<br>
    user_input = input("Enter the number of the keyword you want to remove (comma-separated if multiple), or 'done' to finish: ")<br>
    if user_input.lower() == 'done':<br>
        break<br>
    try:<br>
        to_remove = [int(num) - 1 for num in user_input.split(',')]<br>
        removed_keywords.extend([top_5_keywords[i] for i in to_remove])
        top_5_keywords = [keyword for keyword in top_5_keywords if keyword not in removed_keywords]<br>
    except ValueError:<br>
        print("Invalid input. Please enter the number(s) of the keyword you want to remove.")<br>
<br>
# Task 2: Articles matching the top 5 keywords after removal<br>
keywords_set = set(top_5_keywords)  # Use the remaining keywords<br>
articles_top_keywords = df[df['Keywords'].apply(lambda x: any(keyword in x for keyword in keywords_set))] # filter articles where at least one keyword is found in 'Keywords' column<br> 
print("Number of articles matching top 5 keywords:", len(articles_top_keywords))<br>
<br>

# Task 3: Identify authors discussing the top 5 keywords after removal<br>
author_articles = []  # list to store relevant information from each article<br>
for index, row in df.iterrows():  # iterate through rows of dataframe df<br>
    for keyword in top_5_keywords: # for every keyword in top 5 remaining keywords<br>
        if str(keyword) in row['Keywords']: # check if the keyword is present in 'Keywords' column of current row<br>
            author_articles.append({  # if so, add relevant info to author_articles list<br>
                'Keyword': keyword,<br>
                'Author': row['Author'],<br>
                'Title': row['Title'], <br>
                'URL': row['Permalink'],<br>
                'Description': row['Description'] # 'Description': row['Description'][:250]  # Uncomment this line to limit description length to first 250 characters<br>
            })<br>
author_articles = [dict(t) for t in {tuple(d.items()) for d in author_articles}]  # Remove duplicates by converting to set and back to list<br>
<br>
# Task 4: Word cloud based on descriptions of articles matching the remaining top 5 keywords<br>
descriptions_top_keywords = ' '.join(articles_top_keywords['Description'].dropna()) # join all descriptions in a single string, dropping NaNs<br>
wordcloud = WordCloud(width=1200, height=960).generate(descriptions_top_keywords)  # generate word cloud with the joined descriptions<br>
plt.figure(figsize=(8, 4))<br>
plt.imshow(wordcloud, interpolation='bilinear')<br>
plt.axis('off')<br>
svg_image = BytesIO()<br>
plt.savefig(svg_image, format='svg') # Save word cloud as svg image<br>
encoded_svg = base64.b64encode(svg_image.getvalue()).decode()  # Encoding the svg image to display in HTML report<br>
wordcloud_svg = f"&lt;img src='data:image/svg+xml;base64,{encoded_svg}' width='1200' height='960'/&gt;" <br>
with open("NewsDB-Python/reports/Descriptions_word_cloud.html", "w") as f: # Save image in html report<br>
    f.write(wordcloud_svg)<br>
print("Word cloud saved to NewsDB-Python/reports/Descriptions_word_cloud.html") <br>
<br>
# Output keyword analysis report in Markdown format<br>
report_md = f"# Keyword Analysis Report\n## TASK 1: Display the top five keywords and their frequencies.\n### Which five keywords occur most frequently in the dataset?\n\n"<br>
for keyword in top_5_keywords:  # Output the remaining keywords<br>
    report_md += f"{top_5_keywords.index(keyword) + 1}. {keyword}\n\n"<br>
report_md += "## TASK 2: Articles matching the top five keywords\n### Which articles match the five most frequently occurring keywords?\n\n"<br>
report_md += f"&lt;ol&gt;"<br>
for index, row in articles_top_keywords.iterrows():  # Output titles, authors and descriptions of relevant articles<br>
    report_md += f"&lt;li&gt;\n\n"<br>
    report_md += f"---\n\n"<br>
    report_md += f"**Keyword**: {row['Keywords']}\n\n"<br>
    # report_md += f"{top_5_keywords(keyword)}\n\n"<br>
    report_md += f"\n\n"<br>
    report_md += f"**Title**: &lt;a href='{row['Permalink']}'&gt;{row['Title']}&lt;/a&gt;\n"<br> 
    report_md += f"\n\n" <br>   
    report_md += f"**Author**: {row['Author']}\n"<br>
    report_md += f"\n\n"<br>
    report_md += f"**Description**: {row['Description']}\n\n"<br>
    report_md += f"&lt;/li&gt;"<br>
report_md += f"&lt;/ol&gt;\n\n"<br> 
report_md += "## TASK 3: Identify authors discussing the top five keywords\n### Which authors discuss the top five keywords?\n\n"<br>
report_md += f"&lt;ol&gt;"<br>
for article in author_articles:  # Output relevant info from each article in author_articles list<br>
    report_md += f"&lt;li&gt;\n\n"<br>
    report_md += f"---\n\n" <br>   
    report_md += f"- **Keyword**: {article['Keyword']}\n" <br>  
    report_md += f"- **Author**: {article['Author']}\n"<br>
    report_md += f"- **Title**: &lt;a href='{article['URL']}'&gt;{article['Title']}&lt;/a&gt;\n"<br> 
    report_md += f"- **Description**: {article['Description']}\n\n"<br>  
    report_md += f"&lt;/li&gt;"<br>
report_md += f"&lt;/ol&gt;\n\n"<br> 
report_md += "## TASK 4: Word cloud based on descriptions of all articles in the dataset\n\n"<br>
report_md += f"![image](NewsDB-Python/reports/Descriptions_word_cloud.svg)\n"<br>
with open("NewsDB-Python/reports/keyword_analysis_report.md", "w") as f:  # Save markdown report <br>
    f.write(report_md)<br>
print("Markdown report saved to NewsDB-Python/reports/keyword_analysis_report.md")<br>
<br>

# Output keyword analysis report in HTML format<br>
html_template = """&lt;!DOCTYPE html&gt;<br>
&lt;html lang="en"&gt;<br>

&lt;head&gt;<br>
    &lt;link href="style_article.css" rel="stylesheet"&gt;v
    &lt;meta charset="UTF-8"&gt;<br>
    &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;<br>
    &lt;title&gt;Keyword Analysis Report&lt;/title&gt;<br>
&lt;/head&gt;<br>
&lt;body&gt;<br>
&lt;h1&gt;Keyword Analysis Report&lt;/h1&gt;<br>
&lt;h2&gt;TASK 1: Display the top five keywords and their frequencies. &lt;/h2&gt;<br>
&lt;h4&gt;Which five keywords occur most frequently in the dataset?&lt;/h4&gt;<br>
&lt;ol&gt;{keywords}&lt;/ol&gt;<br>
&lt;hr&gt;<br>
&lt;h2&gt;TASK 2: Articles matching the top five keywords&lt;/h2&gt;<br>
&lt;h4&gt;Which articles match the five most frequently occurring keywords&lt;/h4&gt;<br>
&lt;ol&gt;{articles}&lt;/ol&gt;<br>
&lt;hr&gt;<br>
&lt;h2&gt;TASK 3: Identify authors discussing the top five keywords&lt;/h2&gt;<br>
&lt;h4&gt;Which authors discuss the top five keywords?&lt;/h4&gt;<br>
{author_articles}<br>
&lt;hr&gt;<br>
&lt;h2&gt;TASK 4: Word cloud based on descriptions of all articles in the dataset&lt;/h2&gt;<br>
&lt;div&gt;{wordcloud}&lt;/div&gt;<br>
&lt;/body&gt;<br>
&lt;/html&gt;"""  # HTML template with placeholders for various parts of report<br>
keywords = "\n".join(f'&lt;li&gt;{keyword}&lt;/li&gt;' for keyword in top_5_keywords)<br> 
articles = "\n".join(f'&lt;h3&gt;Keyword: {article["Keyword"]}&lt;/h3&gt;&lt;p&gt;&lt;a href="{row["Permalink"]}"&gt;{row["Title"]}&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;<br> {row["Author"]}:&lt;/strong&gt; {row["Description"]}&lt;/p&gt;&lt;br&gt;&lt;br&gt;' for index, row in articles_top_keywords.iterrows())  <br> 
author_articles = "\n".join(f'&lt;h3&gt;Keyword: {article["Keyword"]}&lt;/h3&gt;&lt;p&gt;Author: {article["Author"]}&lt;/p&gt;&lt;p&gt;Title: &lt;a href="{article["URL"]}"&gt;<br> {article["Title"]}&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Description: {article["Description"]}&lt;/p&gt;' for article in author_articles)  <br> 
output = html_template.format(keywords=keywords, articles=articles, wordcloud=wordcloud_svg, author_articles=author_articles) # Format the HTML template with the actual data<br> 
with open('NewsDB-Python/reports/report.html', 'w') as f:  # Save the html report <br> 
    f.write(output)<br> 
print("HTML report saved to NewsDB-Python/reports/report.html")<br>    
                </code>
        </main>
       <footer>
            <div id="footer">
               <div class="copyright">
                  <div><a href="https://creativecommons.org/licenses/by/4.0/legalcode"><img src="img/cc.svg" class="copyright_logo" alt="Creative Commons License"><img src="img/by.svg" class="copyright_logo" alt="Attribution 4.0 International"></a></div>
                  <div>
                     2024 Klara Chlupata, Einar Hannerz, Andre Rodewald and Victor Villavicencio.
                     </div>
               </div>
            </div>
         </footer>
    </body>
</html>
